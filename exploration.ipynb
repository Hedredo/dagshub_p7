{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hedredo/dagshub_p7/blob/main/exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8toksSU9EOt"
      },
      "source": [
        "# **How-To MLflow**\n",
        "\n",
        "**How to use MLflow to log params and metrics**\n",
        "\n",
        "```\n",
        "with mlflow.start_run():\n",
        "  # Your training code here...\n",
        "  mlflow.log_metric('accuracy', 42)\n",
        "  mlflow.log_param('Param name', 'Value')\n",
        "```\n",
        "\n",
        "\n",
        "**Turn on autologging for most popular ML frameworks**<br>\n",
        "For more info and list of supported frameworks, see: https://mlflow.org/docs/latest/tracking.html#automatic-logging<br>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "mlflow.autolog()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SeCRp5TWz-P"
      },
      "source": [
        "# **Configuration de l'environnement**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JvR9_vR4VyK",
        "outputId": "d0454317-a8c5-44ad-b913-e1b754908a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.9/247.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.6/565.6 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q dagshub mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSCY40Pa66Yv",
        "outputId": "36a47232-19fc-4a65-bb83-bf595c42e647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "# Check the CUDA version with the T4 GPU instance\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AgChoQUZ97AN"
      },
      "outputs": [],
      "source": [
        "import dagshub\n",
        "import mlflow\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import spacy\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQXWFolR6wXT",
        "outputId": "548293ed-f323-4b92-9768-faf4a4e46368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow framework: GPU is available\n",
            "Pytorch framework: GPU is available\n"
          ]
        }
      ],
      "source": [
        "print(\"Tensorflow framework: GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
        "print(\"Pytorch framework: GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229,
          "referenced_widgets": [
            "185b3fd51a024e08a306a6e0637acdd9",
            "e63383a6a9734f0f827bd482cc6b3ed5"
          ]
        },
        "id": "RaoRSbYq-DUX",
        "outputId": "f6b7909d-d4e0-48e6-c5d1-f6deabc77c2a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
              "</pre>\n"
            ],
            "text/plain": [
              "                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "185b3fd51a024e08a306a6e0637acdd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Open the following link in your browser to authorize the client:\n",
            "https://dagshub.com/login/oauth/authorize?state=815fd434-bd5c-4e39-b248-3384ce77b4a1&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=7acf2878dcc02b42cf6e8cb4f3e11ec1b33da8d0fdbf5684b564cca34cf618a4\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as hedredo\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as hedredo\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"hedredo/dagshub_p7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"hedredo/dagshub_p7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository hedredo/dagshub_p7 initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository hedredo/dagshub_p7 initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to 314\n"
          ]
        }
      ],
      "source": [
        "# Remove FutureWarning alerts\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# Initialize dagshub repo\n",
        "dagshub.init(repo_owner='hedredo', repo_name='dagshub_p7', mlflow=True)\n",
        "\n",
        "# Set a random seed\n",
        "SEED = 314\n",
        "np.random.seed(SEED)\n",
        "print(\"Random seed set to\", SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7DZPq1vJMuN",
        "outputId": "0d924e67-442a-4d93-ae62-777f85bf7856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm25hDnuHRDQ",
        "outputId": "f1d0f364-df3a-4daa-e533-70e5acccba9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Download the small language model for spacy\n",
        "spacy.cli.download('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vtiCJZZ7iGz"
      },
      "source": [
        "# **Chargement des données**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6xtWYfH2XGvn"
      },
      "outputs": [],
      "source": [
        "# Path to the csv file\n",
        "path = \"/content/drive/MyDrive/Formation & Emploi/OpenClassRooms/OC Projets de formation/Projet 7/training.1600000.processed.noemoticon.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xHMKuU6zXVgQ"
      },
      "outputs": [],
      "source": [
        "# Read the file\n",
        "df = pd.read_csv(\n",
        "    path,\n",
        "    header=None,\n",
        "    names=['target', 'ids', 'date', 'flag', 'user', 'text'],\n",
        "    parse_dates=['date'],\n",
        "    encoding='utf-8',\n",
        "    encoding_errors='replace' # replace the errors with unicode symbol � (U+FFFD)\n",
        "    )\n",
        "\n",
        "# Assign the len of the original file\n",
        "df_len = len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SzHxOZ2-pY2",
        "outputId": "b6bbea83-46b7-4b11-dacb-e272b0697bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1600000 entries, 0 to 1599999\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count    Dtype         \n",
            "---  ------  --------------    -----         \n",
            " 0   target  1600000 non-null  int64         \n",
            " 1   ids     1600000 non-null  int64         \n",
            " 2   date    1600000 non-null  datetime64[ns]\n",
            " 3   flag    1600000 non-null  object        \n",
            " 4   user    1600000 non-null  object        \n",
            " 5   text    1600000 non-null  object        \n",
            "dtypes: datetime64[ns](1), int64(2), object(3)\n",
            "memory usage: 73.2+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKXXnXWKbq8Z"
      },
      "source": [
        "- target : cible composée de 0:negative et 4:positive uniforme (environ 50 50)\n",
        "- id : identifiant unique pour chaque tweet. Un tweet peut être en double avec un même id annoté soit positif (4) soit négatif (0). C'est le seul champs qui peut varier.\n",
        "- date : la date du tweet (l'heure n'est pas fournie). PDT est l'heure du pacifique. Tous les tweets sont en PDT et la valeur est retiré lors du parsing\n",
        "- flag : toutes les valeurs sont à no query, useless\n",
        "- user : nom de l'utilisateur qui a posté le tweet. Peut être présent sur plusieurs tweets.\n",
        "- text : le texte du tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GerSebNYbsQT"
      },
      "source": [
        "**BLOC-NOTES**\n",
        "- Lire la description du projet\n",
        "- Regarder les notes google drive de PA\n",
        "- Faire un tableau markdown pour synthétiser le contenu\n",
        "- Importer uniquement les données utiles\n",
        "- Convertir les données dans le bon format\n",
        "- Faire une EDA et voir par exemple si le jour, l'heure, le mois ont un impact sur le sentiment\n",
        "- Faire une wordcloud pour voir les mots les plus fréquents selon la target\n",
        "- Faire un comptage de mots, ponctuation, hashtag, mention, url et regarder si leur nombre a un impact sur la classe\n",
        "- Préparer les corpus avec différentes options de prétraitement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcLwgdx98mIg"
      },
      "source": [
        "# **Séparation des données**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCL9XJz19D8v",
        "outputId": "dd60ec12-e13b-48c9-f337-d2d9a962b2d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling the data with 0.1 fraction\n",
            "X_train shape: (128000,)\n",
            "X_test shape: (32000,)\n",
            "y_train shape: (128000,)\n",
            "y_test shape: (32000,)\n"
          ]
        }
      ],
      "source": [
        "# Define if working with a sample\n",
        "sampling = True\n",
        "proportion = 0.1\n",
        "\n",
        "# Split the data with sampling or not\n",
        "if sampling:\n",
        "    if len(df) != df_len:\n",
        "        print(\"Dataframe has already been sampled\")\n",
        "    else:\n",
        "        print(f\"Sampling the data with {proportion} fraction\")\n",
        "        df = df.sample(frac=proportion, random_state=SEED)\n",
        "\n",
        "# Define X and y\n",
        "X = df['text']\n",
        "y = df['target']\n",
        "\n",
        "# Split the data with a 0.2 test size\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=SEED\n",
        "    )\n",
        "\n",
        "# Display shape of splits\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oatQI0vyGvLZ"
      },
      "source": [
        "# **Options de standardisation des textes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqnO5skQ_ysV"
      },
      "source": [
        "Voici une liste de 10 moyens de standardiser votre corpus de tweets pour l'analyse de sentiments :\n",
        "\n",
        "1. **Conversion en minuscules** : Transformer tous les caractères en minuscules pour uniformiser le texte.\n",
        "2. **Suppression de la ponctuation** : Enlever tous les signes de ponctuation qui peuvent ne pas être pertinents pour l'analyse.\n",
        "3. **Élimination des mots vides (stop words)** : Supprimer les mots courants qui n'ajoutent pas de valeur sémantique significative (comme \"le\", \"la\", \"de\", etc.).\n",
        "4. **Stemming** : Réduire les mots à leur racine pour traiter les variations morphologiques (par exemple, \"aimant\", \"aimer\", \"aimé\" deviennent \"aim\").\n",
        "5. **Lemmatisation** : Transformer les mots en leur forme de base ou canonique (par exemple, \"étudiants\" devient \"étudiant\").\n",
        "6. **Suppression des nombres** : Enlever les chiffres qui peuvent ne pas être utiles pour l'analyse de sentiments.\n",
        "7. **Traitement des URL** : Remplacer les liens par un token spécifique comme `<URL>` pour uniformiser le texte.\n",
        "8. **Gestion des mentions** : Remplacer les @utilisateur par un token comme `<MENTION>` pour éviter les informations spécifiques inutiles.\n",
        "9. **Traitement des hashtags** : Extraire le mot-clé du hashtag (par exemple, \"#bonheur\" devient \"bonheur\") pour conserver le sens.\n",
        "10. **Gestion des emojis et émoticônes** : Remplacer les emojis par leur signification textuelle ou les supprimer si nécessaire (par exemple, \"😊\" devient \"heureux\").\n",
        "\n",
        "Ces standardisations peuvent vous aider à améliorer la qualité de vos données et potentiellement les performances de vos modèles de classification en réduisant le bruit et en uniformisant le corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QuUVzMvfIQ6m"
      },
      "outputs": [],
      "source": [
        "# Load the en_core_web_sm model\n",
        "spacy.prefer_gpu(gpu_id=0)\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT1Uswn_NDCO"
      },
      "source": [
        "**EDA**\n",
        "\n",
        "* Longueur str\n",
        "* Nombre de tokens\n",
        "* Longueur moyenne / min / max / std token\n",
        "* Compte le nombre d'erreurs unidecode\n",
        "* Compte le nombre de tags\n",
        "* Comptre le nombre de hashtags\n",
        "* Compte le nombre de mentions\n",
        "* Compte le nombre d'emoji\n",
        "* Compte le nombre d'URL\n",
        "* Etc..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TP5AyiSqK6Sr"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(\n",
        "        text:str,\n",
        "        lowercase:bool=True,\n",
        "        root:str='raw',\n",
        "        rm_punct:bool=True,\n",
        "        rm_stopwords:bool=True,\n",
        "        rm_numbers:bool=True,\n",
        "        rm_url:bool=True,\n",
        "        rm_mention:bool=True,\n",
        "        rm_hashtag:bool=True,\n",
        "        rm_emoji:bool=True\n",
        "        ):\n",
        "    # Root error management\n",
        "    match root:\n",
        "        case 'lemma'|'stem'|'raw':\n",
        "            pass\n",
        "        case _:\n",
        "            raise ValueError(\"root must be 'lemma', 'stem' or 'raw'\")\n",
        "\n",
        "    # TO WRITE\n",
        "\n",
        "\n",
        "    # Return the preprocessed text\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLfraRn4M4zL",
        "outputId": "428d96ca-ae3f-4a42-c96d-4153dba3fc43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "So far, most Habbos would want to dance to &quot;Love Story&quot; (Taylor Swift) or &quot;Tonight I Celebrate My Love&quot; (Roberta Flack). Amusing. \n"
          ]
        }
      ],
      "source": [
        "text = X_train.sample(1).values[0]\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EO9bY6zUNAUX",
        "outputId": "cfed9dcc-eb21-4dd6-d50e-28e44acddf67"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'So far, most Habbos would want to dance to &quot;Love Story&quot; (Taylor Swift) or &quot;Tonight I Celebrate My Love&quot; (Roberta Flack). Amusing. '"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Création de la figure avec 4 plots en format (2, 2)\n",
        "fig, ax = plt.subplots(2, 2, figsize=(12, 8), tight_layout=True)\n",
        "fig.suptitle('Distribution du nombre de caractères dans les colonnes product_name et description', fontweight='bold')\n",
        "\n",
        "# Pour chaque colonne, on crée un histogramme et un boxplot\n",
        "for i, (column, color) in enumerate(zip(\n",
        "    ('product_name', 'description'),\n",
        "    ('deepskyblue', 'crimson'),\n",
        "    )):\n",
        "    # On calcule le nombre de caractères pour chaque produit\n",
        "    series = text_df[column].str.len()\n",
        "    # On calcule le min, max et la moyenne\n",
        "    min, max, mean = series.min(), series.max(), series.mean()\n",
        "    # On crée l'histogramme et on ajoute les lignes pour la moyenne, le min et le max\n",
        "    series.hist(bins=100, color=color, alpha=0.75, ax=ax[0, i]).set(xlabel='Nombre de caractères', ylabel='Nombre de produits', title=f'Histogramme: {column}')\n",
        "    ax[0, i].axvline(mean, color='black', linestyle='dashed', linewidth=2)\n",
        "    ax[0, i].axvline(min, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].axvline(max, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].text(mean, 2, f'Moyenne: {mean:.2f}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(min, 2, f'Min: {min}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(max, 2, f'Max: {max}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    # On crée le boxplot\n",
        "    series.plot(kind='box', vert=False, color=color, ax=ax[1, i]).set(xlabel='Nombre de caractères', title=f'Boxplot: {column}')\n",
        "    ax[1, i].set_yticks([])\n",
        "# On affiche la figure\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Création de la figure avec 4 plots en format (2, 2)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m), tight_layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m fig\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution du nombre de tokens dans les colonnes product_name et description\u001b[39m\u001b[38;5;124m'\u001b[39m, fontweight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Pour chaque colonne, on crée un histogramme et un boxplot\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# Création de la figure avec 4 plots en format (2, 2)\n",
        "fig, ax = plt.subplots(2, 1, figsize=(12, 8), tight_layout=True)\n",
        "fig.suptitle('Distribution du nombre de tokens dans les colonnes product_name et description', fontweight='bold')\n",
        "\n",
        "# Pour chaque colonne, on crée un histogramme et un boxplot\n",
        "for i, (column, color) in enumerate(zip(\n",
        "    ('text', ),\n",
        "    ('deepskyblue', ),\n",
        "    )):\n",
        "    # On calcule le nombre de caractères pour chaque produit\n",
        "    series = pd.Series([len(doc) for doc in nlp.pipe(df[column].values)])\n",
        "    # On calcule le min, max et la moyenne\n",
        "    min, max, mean = series.min(), series.max(), series.mean()\n",
        "    # On crée l'histogramme et on ajoute les lignes pour la moyenne, le min et le max\n",
        "    series.hist(bins=100, color=color, alpha=0.75, ax=ax[0, i]).set(xlabel='Nombre de tokens', ylabel='Nombre de produits', title=f'Histogramme: {column}')\n",
        "    ax[0, i].axvline(mean, color='black', linestyle='dashed', linewidth=2)\n",
        "    ax[0, i].axvline(min, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].axvline(max, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].text(mean, 2, f'Moyenne: {mean:.2f}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(min, 2, f'Min: {min}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(max, 2, f'Max: {max}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    # On crée le boxplot\n",
        "    series.plot(kind='box', vert=False, color=color, ax=ax[1, i]).set(xlabel='Nombre de tokens', title=f'Boxplot: {column}')\n",
        "    ax[1, i].set_yticks([])\n",
        "# On affiche la figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Création de la figure avec 4 plots en format (2, 2)\n",
        "fig, ax = plt.subplots(2, 2, figsize=(12, 8), tight_layout=True)\n",
        "fig.suptitle('Distribution de la longueur des tokens dans les colonnes product_name et description', fontweight='bold')\n",
        "\n",
        "# Pour chaque colonne, on crée un histogramme et un boxplot\n",
        "for i, (column, color) in enumerate(zip(\n",
        "    ('product_name', 'description'),\n",
        "    ('deepskyblue', 'crimson'),\n",
        "    )):\n",
        "    # On calcule la longueur de chaque token pour chaque produit\n",
        "    series = pd.Series([len(token) for doc in nlp.pipe(text_df[column].values) for token in doc])\n",
        "    # On calcule le min, max et la moyenne\n",
        "    min, max, mean = series.min(), series.max(), series.mean()\n",
        "    # On crée l'histogramme et on ajoute les lignes pour la moyenne, le min et le max\n",
        "    series.hist(bins=100, color=color, alpha=0.75, ax=ax[0, i]).set(xlabel='Longueur des tokens', ylabel='Nombre de tokens', title=f'Histogramme: {column}')\n",
        "    ax[0, i].axvline(mean, color='black', linestyle='dashed', linewidth=2)\n",
        "    ax[0, i].axvline(min, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].axvline(max, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].text(mean, 2, f'Moyenne: {mean:.2f}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(min, 2, f'Min: {min}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(max, 2, f'Max: {max}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    # On crée le boxplot\n",
        "    series.plot(kind='box', vert=False, color=color, ax=ax[1, i]).set(xlabel='Longueur des tokens', title=f'Boxplot: {column}')\n",
        "    ax[1, i].set_yticks([])\n",
        "# On affiche la figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a pattern to match urls in the description column\n",
        "url = r\"www\\.\\S+\" # correct pattern for urls\n",
        "email = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n",
        "hashtag = r\"#\\S+\"\n",
        "mentions = r\"@\\S+\"\n",
        "emoji = r\"[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251]+\"\n",
        "\n",
        "# Find and display the urls that match the pattern in the product and description columns\n",
        "print(\"Recherche de pattern de type URL\")\n",
        "print(text_df[\"product_name\"].str.findall(url).apply(len).value_counts().index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define an email pattern to match emails in the description column\n",
        "email = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n",
        "\n",
        "# Find and display the urls that match the pattern in the product and description columns\n",
        "print(\"Recherche de pattern de type Email\")\n",
        "print(text_df[\"product_name\"].str.findall(email).apply(len).value_counts().index)\n",
        "print(text_df[\"description\"].str.findall(email).apply(len).value_counts().index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_custom(data, items_per_line=5):\n",
        "    \"\"\"\n",
        "    Affiche les éléments de la liste avec un nombre fixe d'éléments par ligne.\n",
        "    \n",
        "    :param data: La liste de données à afficher.\n",
        "    :param items_per_line: Nombre d'éléments par ligne.\n",
        "    \"\"\"\n",
        "    for i in range(0, len(data), items_per_line):\n",
        "        print(data[i:i + items_per_line])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affiche tous les tokens de longueur supérieure ou égal à 13 caractères\n",
        "print_custom(list(\n",
        "    set(\n",
        "    [token.text for doc in nlp.pipe(text_df['product_name'].values) for token in doc if len(token.text) >= 13]\n",
        "    ).union(set(\n",
        "        [token.text for doc in nlp.pipe(text_df['description'].values) for token in doc if len(token.text) >= 13])\n",
        "        )\n",
        ")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Corrige les exceptions suivantes lors de la tokenisation\n",
        "for column in ('product_name', 'description'):\n",
        "    text_df[column] = text_df[column].str.replace(r'(?<=\\w)[,-_.!()\"]+(?=\\w)', ' ', regex=True) # Gère les caractères de type ,-_.!() qui sont au milieu d'une chaîne de caractères\n",
        "    text_df[column] = text_df[column].str.replace(r'[,]+(?=\\w)', ' ', regex=True) # Gère les virgules qui sont au début d'une chaîne de caractères"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affiche tous les tokens de longueur égal à 1 caractère\n",
        "print_custom(list(\n",
        "    set(\n",
        "    [token.text for doc in nlp.pipe(text_df['product_name'].values) for token in doc if len(token.text) == 1]\n",
        "    ).union(set(\n",
        "        [token.text for doc in nlp.pipe(text_df['description'].values) for token in doc if len(token.text) == 1])\n",
        "        )\n",
        ")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Corrige les exceptions suivantes lors de la tokenisation\n",
        "for column in ('product_name', 'description'):\n",
        "    text_df[column] = text_df[column].str.replace(r'\\u2028', r'\\n', regex=True) # Gère les caractères de type \\u2028 comme un saut de ligne\n",
        "    text_df[column] = text_df[column].str.replace(r'\\xa0', ' ', regex=True) # Gère les caractères de type \\xa0 comme un espace\n",
        "    text_df[column] = text_df[column].str.replace(r'�', '', regex=True) # Gère les caractères de type � comme une chaîne vide"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "185b3fd51a024e08a306a6e0637acdd9": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e63383a6a9734f0f827bd482cc6b3ed5",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠸</span> Waiting for authorization\n</pre>\n",
                  "text/plain": "\u001b[32m⠸\u001b[0m Waiting for authorization\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "e63383a6a9734f0f827bd482cc6b3ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
