{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hedredo/dagshub_p7/blob/main/exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8toksSU9EOt"
      },
      "source": [
        "# **How-To MLflow**\n",
        "\n",
        "**How to use MLflow to log params and metrics**\n",
        "\n",
        "```\n",
        "with mlflow.start_run():\n",
        "  # Your training code here...\n",
        "  mlflow.log_metric('accuracy', 42)\n",
        "  mlflow.log_param('Param name', 'Value')\n",
        "```\n",
        "\n",
        "\n",
        "**Turn on autologging for most popular ML frameworks**<br>\n",
        "For more info and list of supported frameworks, see: https://mlflow.org/docs/latest/tracking.html#automatic-logging<br>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "mlflow.autolog()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SeCRp5TWz-P"
      },
      "source": [
        "# **Configuration de l'environnement**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JvR9_vR4VyK",
        "outputId": "d0454317-a8c5-44ad-b913-e1b754908a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m247.9/247.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m565.6/565.6 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q dagshub mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSCY40Pa66Yv",
        "outputId": "36a47232-19fc-4a65-bb83-bf595c42e647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "# Check the CUDA version with the T4 GPU instance\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AgChoQUZ97AN"
      },
      "outputs": [],
      "source": [
        "import dagshub\n",
        "import mlflow\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import spacy\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQXWFolR6wXT",
        "outputId": "548293ed-f323-4b92-9768-faf4a4e46368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow framework: GPU is available\n",
            "Pytorch framework: GPU is available\n"
          ]
        }
      ],
      "source": [
        "print(\"Tensorflow framework: GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
        "print(\"Pytorch framework: GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229,
          "referenced_widgets": [
            "185b3fd51a024e08a306a6e0637acdd9",
            "e63383a6a9734f0f827bd482cc6b3ed5"
          ]
        },
        "id": "RaoRSbYq-DUX",
        "outputId": "f6b7909d-d4e0-48e6-c5d1-f6deabc77c2a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">â—â—â— AUTHORIZATION REQUIRED â—â—â—</span>                                        \n",
              "</pre>\n"
            ],
            "text/plain": [
              "                                       \u001b[1mâ—â—â— AUTHORIZATION REQUIRED â—â—â—\u001b[0m                                        \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "185b3fd51a024e08a306a6e0637acdd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Open the following link in your browser to authorize the client:\n",
            "https://dagshub.com/login/oauth/authorize?state=815fd434-bd5c-4e39-b248-3384ce77b4a1&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=7acf2878dcc02b42cf6e8cb4f3e11ec1b33da8d0fdbf5684b564cca34cf618a4\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as hedredo\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as hedredo\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"hedredo/dagshub_p7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"hedredo/dagshub_p7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository hedredo/dagshub_p7 initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository hedredo/dagshub_p7 initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to 314\n"
          ]
        }
      ],
      "source": [
        "# Remove FutureWarning alerts\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# Initialize dagshub repo\n",
        "dagshub.init(repo_owner='hedredo', repo_name='dagshub_p7', mlflow=True)\n",
        "\n",
        "# Set a random seed\n",
        "SEED = 314\n",
        "np.random.seed(SEED)\n",
        "print(\"Random seed set to\", SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7DZPq1vJMuN",
        "outputId": "0d924e67-442a-4d93-ae62-777f85bf7856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm25hDnuHRDQ",
        "outputId": "f1d0f364-df3a-4daa-e533-70e5acccba9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Download the small language model for spacy\n",
        "spacy.cli.download('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vtiCJZZ7iGz"
      },
      "source": [
        "# **Chargement des donnÃ©es**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6xtWYfH2XGvn"
      },
      "outputs": [],
      "source": [
        "# Path to the csv file\n",
        "path = \"/content/drive/MyDrive/Formation & Emploi/OpenClassRooms/OC Projets de formation/Projet 7/training.1600000.processed.noemoticon.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xHMKuU6zXVgQ"
      },
      "outputs": [],
      "source": [
        "# Read the file\n",
        "df = pd.read_csv(\n",
        "    path,\n",
        "    header=None,\n",
        "    names=['target', 'ids', 'date', 'flag', 'user', 'text'],\n",
        "    parse_dates=['date'],\n",
        "    encoding='utf-8',\n",
        "    encoding_errors='replace' # replace the errors with unicode symbol ï¿½ (U+FFFD)\n",
        "    )\n",
        "\n",
        "# Assign the len of the original file\n",
        "df_len = len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SzHxOZ2-pY2",
        "outputId": "b6bbea83-46b7-4b11-dacb-e272b0697bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1600000 entries, 0 to 1599999\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count    Dtype         \n",
            "---  ------  --------------    -----         \n",
            " 0   target  1600000 non-null  int64         \n",
            " 1   ids     1600000 non-null  int64         \n",
            " 2   date    1600000 non-null  datetime64[ns]\n",
            " 3   flag    1600000 non-null  object        \n",
            " 4   user    1600000 non-null  object        \n",
            " 5   text    1600000 non-null  object        \n",
            "dtypes: datetime64[ns](1), int64(2), object(3)\n",
            "memory usage: 73.2+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKXXnXWKbq8Z"
      },
      "source": [
        "- target : cible composÃ©e de 0:negative et 4:positive uniforme (environ 50 50)\n",
        "- id : identifiant unique pour chaque tweet. Un tweet peut Ãªtre en double avec un mÃªme id annotÃ© soit positif (4) soit nÃ©gatif (0). C'est le seul champs qui peut varier.\n",
        "- date : la date du tweet (l'heure n'est pas fournie). PDT est l'heure du pacifique. Tous les tweets sont en PDT et la valeur est retirÃ© lors du parsing\n",
        "- flag : toutes les valeurs sont Ã  no query, useless\n",
        "- user : nom de l'utilisateur qui a postÃ© le tweet. Peut Ãªtre prÃ©sent sur plusieurs tweets.\n",
        "- text : le texte du tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GerSebNYbsQT"
      },
      "source": [
        "**BLOC-NOTES**\n",
        "- Lire la description du projet\n",
        "- Regarder les notes google drive de PA\n",
        "- Faire un tableau markdown pour synthÃ©tiser le contenu\n",
        "- Importer uniquement les donnÃ©es utiles\n",
        "- Convertir les donnÃ©es dans le bon format\n",
        "- Faire une EDA et voir par exemple si le jour, l'heure, le mois ont un impact sur le sentiment\n",
        "- Faire une wordcloud pour voir les mots les plus frÃ©quents selon la target\n",
        "- Faire un comptage de mots, ponctuation, hashtag, mention, url et regarder si leur nombre a un impact sur la classe\n",
        "- PrÃ©parer les corpus avec diffÃ©rentes options de prÃ©traitement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcLwgdx98mIg"
      },
      "source": [
        "# **SÃ©paration des donnÃ©es**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCL9XJz19D8v",
        "outputId": "dd60ec12-e13b-48c9-f337-d2d9a962b2d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling the data with 0.1 fraction\n",
            "X_train shape: (128000,)\n",
            "X_test shape: (32000,)\n",
            "y_train shape: (128000,)\n",
            "y_test shape: (32000,)\n"
          ]
        }
      ],
      "source": [
        "# Define if working with a sample\n",
        "sampling = True\n",
        "proportion = 0.1\n",
        "\n",
        "# Split the data with sampling or not\n",
        "if sampling:\n",
        "    if len(df) != df_len:\n",
        "        print(\"Dataframe has already been sampled\")\n",
        "    else:\n",
        "        print(f\"Sampling the data with {proportion} fraction\")\n",
        "        df = df.sample(frac=proportion, random_state=SEED)\n",
        "\n",
        "# Define X and y\n",
        "X = df['text']\n",
        "y = df['target']\n",
        "\n",
        "# Split the data with a 0.2 test size\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=SEED\n",
        "    )\n",
        "\n",
        "# Display shape of splits\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oatQI0vyGvLZ"
      },
      "source": [
        "# **Options de standardisation des textes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqnO5skQ_ysV"
      },
      "source": [
        "Voici une liste de 10 moyens de standardiser votre corpus de tweets pour l'analyse de sentimentsâ€¯:\n",
        "\n",
        "1. **Conversion en minuscules**â€¯: Transformer tous les caractÃ¨res en minuscules pour uniformiser le texte.\n",
        "2. **Suppression de la ponctuation**â€¯: Enlever tous les signes de ponctuation qui peuvent ne pas Ãªtre pertinents pour l'analyse.\n",
        "3. **Ã‰limination des mots vides (stop words)**â€¯: Supprimer les mots courants qui n'ajoutent pas de valeur sÃ©mantique significative (comme \"le\", \"la\", \"de\", etc.).\n",
        "4. **Stemming**â€¯: RÃ©duire les mots Ã  leur racine pour traiter les variations morphologiques (par exemple, \"aimant\", \"aimer\", \"aimÃ©\" deviennent \"aim\").\n",
        "5. **Lemmatisation**â€¯: Transformer les mots en leur forme de base ou canonique (par exemple, \"Ã©tudiants\" devient \"Ã©tudiant\").\n",
        "6. **Suppression des nombres**â€¯: Enlever les chiffres qui peuvent ne pas Ãªtre utiles pour l'analyse de sentiments.\n",
        "7. **Traitement des URL**â€¯: Remplacer les liens par un token spÃ©cifique comme `<URL>` pour uniformiser le texte.\n",
        "8. **Gestion des mentions**â€¯: Remplacer les @utilisateur par un token comme `<MENTION>` pour Ã©viter les informations spÃ©cifiques inutiles.\n",
        "9. **Traitement des hashtags**â€¯: Extraire le mot-clÃ© du hashtag (par exemple, \"#bonheur\" devient \"bonheur\") pour conserver le sens.\n",
        "10. **Gestion des emojis et Ã©moticÃ´nes**â€¯: Remplacer les emojis par leur signification textuelle ou les supprimer si nÃ©cessaire (par exemple, \"ğŸ˜Š\" devient \"heureux\").\n",
        "\n",
        "Ces standardisations peuvent vous aider Ã  amÃ©liorer la qualitÃ© de vos donnÃ©es et potentiellement les performances de vos modÃ¨les de classification en rÃ©duisant le bruit et en uniformisant le corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QuUVzMvfIQ6m"
      },
      "outputs": [],
      "source": [
        "# Load the en_core_web_sm model\n",
        "spacy.prefer_gpu(gpu_id=0)\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT1Uswn_NDCO"
      },
      "source": [
        "**EDA**\n",
        "\n",
        "* Longueur str\n",
        "* Nombre de tokens\n",
        "* Longueur moyenne / min / max / std token\n",
        "* Compte le nombre d'erreurs unidecode\n",
        "* Compte le nombre de tags\n",
        "* Comptre le nombre de hashtags\n",
        "* Compte le nombre de mentions\n",
        "* Compte le nombre d'emoji\n",
        "* Compte le nombre d'URL\n",
        "* Etc..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TP5AyiSqK6Sr"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(\n",
        "        text:str,\n",
        "        lowercase:bool=True,\n",
        "        root:str='raw',\n",
        "        rm_punct:bool=True,\n",
        "        rm_stopwords:bool=True,\n",
        "        rm_numbers:bool=True,\n",
        "        rm_url:bool=True,\n",
        "        rm_mention:bool=True,\n",
        "        rm_hashtag:bool=True,\n",
        "        rm_emoji:bool=True\n",
        "        ):\n",
        "    # Root error management\n",
        "    match root:\n",
        "        case 'lemma'|'stem'|'raw':\n",
        "            pass\n",
        "        case _:\n",
        "            raise ValueError(\"root must be 'lemma', 'stem' or 'raw'\")\n",
        "\n",
        "    # TO WRITE\n",
        "\n",
        "\n",
        "    # Return the preprocessed text\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLfraRn4M4zL",
        "outputId": "428d96ca-ae3f-4a42-c96d-4153dba3fc43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "So far, most Habbos would want to dance to &quot;Love Story&quot; (Taylor Swift) or &quot;Tonight I Celebrate My Love&quot; (Roberta Flack). Amusing. \n"
          ]
        }
      ],
      "source": [
        "text = X_train.sample(1).values[0]\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EO9bY6zUNAUX",
        "outputId": "cfed9dcc-eb21-4dd6-d50e-28e44acddf67"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'So far, most Habbos would want to dance to &quot;Love Story&quot; (Taylor Swift) or &quot;Tonight I Celebrate My Love&quot; (Roberta Flack). Amusing. '"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CrÃ©ation de la figure avec 4 plots en format (2, 2)\n",
        "fig, ax = plt.subplots(2, 2, figsize=(12, 8), tight_layout=True)\n",
        "fig.suptitle('Distribution du nombre de caractÃ¨res dans les colonnes product_name et description', fontweight='bold')\n",
        "\n",
        "# Pour chaque colonne, on crÃ©e un histogramme et un boxplot\n",
        "for i, (column, color) in enumerate(zip(\n",
        "    ('product_name', 'description'),\n",
        "    ('deepskyblue', 'crimson'),\n",
        "    )):\n",
        "    # On calcule le nombre de caractÃ¨res pour chaque produit\n",
        "    series = text_df[column].str.len()\n",
        "    # On calcule le min, max et la moyenne\n",
        "    min, max, mean = series.min(), series.max(), series.mean()\n",
        "    # On crÃ©e l'histogramme et on ajoute les lignes pour la moyenne, le min et le max\n",
        "    series.hist(bins=100, color=color, alpha=0.75, ax=ax[0, i]).set(xlabel='Nombre de caractÃ¨res', ylabel='Nombre de produits', title=f'Histogramme: {column}')\n",
        "    ax[0, i].axvline(mean, color='black', linestyle='dashed', linewidth=2)\n",
        "    ax[0, i].axvline(min, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].axvline(max, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].text(mean, 2, f'Moyenne: {mean:.2f}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(min, 2, f'Min: {min}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(max, 2, f'Max: {max}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    # On crÃ©e le boxplot\n",
        "    series.plot(kind='box', vert=False, color=color, ax=ax[1, i]).set(xlabel='Nombre de caractÃ¨res', title=f'Boxplot: {column}')\n",
        "    ax[1, i].set_yticks([])\n",
        "# On affiche la figure\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# CrÃ©ation de la figure avec 4 plots en format (2, 2)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m), tight_layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m fig\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution du nombre de tokens dans les colonnes product_name et description\u001b[39m\u001b[38;5;124m'\u001b[39m, fontweight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Pour chaque colonne, on crÃ©e un histogramme et un boxplot\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# CrÃ©ation de la figure avec 4 plots en format (2, 2)\n",
        "fig, ax = plt.subplots(2, 1, figsize=(12, 8), tight_layout=True)\n",
        "fig.suptitle('Distribution du nombre de tokens dans les colonnes product_name et description', fontweight='bold')\n",
        "\n",
        "# Pour chaque colonne, on crÃ©e un histogramme et un boxplot\n",
        "for i, (column, color) in enumerate(zip(\n",
        "    ('text', ),\n",
        "    ('deepskyblue', ),\n",
        "    )):\n",
        "    # On calcule le nombre de caractÃ¨res pour chaque produit\n",
        "    series = pd.Series([len(doc) for doc in nlp.pipe(df[column].values)])\n",
        "    # On calcule le min, max et la moyenne\n",
        "    min, max, mean = series.min(), series.max(), series.mean()\n",
        "    # On crÃ©e l'histogramme et on ajoute les lignes pour la moyenne, le min et le max\n",
        "    series.hist(bins=100, color=color, alpha=0.75, ax=ax[0, i]).set(xlabel='Nombre de tokens', ylabel='Nombre de produits', title=f'Histogramme: {column}')\n",
        "    ax[0, i].axvline(mean, color='black', linestyle='dashed', linewidth=2)\n",
        "    ax[0, i].axvline(min, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].axvline(max, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].text(mean, 2, f'Moyenne: {mean:.2f}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(min, 2, f'Min: {min}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(max, 2, f'Max: {max}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    # On crÃ©e le boxplot\n",
        "    series.plot(kind='box', vert=False, color=color, ax=ax[1, i]).set(xlabel='Nombre de tokens', title=f'Boxplot: {column}')\n",
        "    ax[1, i].set_yticks([])\n",
        "# On affiche la figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CrÃ©ation de la figure avec 4 plots en format (2, 2)\n",
        "fig, ax = plt.subplots(2, 2, figsize=(12, 8), tight_layout=True)\n",
        "fig.suptitle('Distribution de la longueur des tokens dans les colonnes product_name et description', fontweight='bold')\n",
        "\n",
        "# Pour chaque colonne, on crÃ©e un histogramme et un boxplot\n",
        "for i, (column, color) in enumerate(zip(\n",
        "    ('product_name', 'description'),\n",
        "    ('deepskyblue', 'crimson'),\n",
        "    )):\n",
        "    # On calcule la longueur de chaque token pour chaque produit\n",
        "    series = pd.Series([len(token) for doc in nlp.pipe(text_df[column].values) for token in doc])\n",
        "    # On calcule le min, max et la moyenne\n",
        "    min, max, mean = series.min(), series.max(), series.mean()\n",
        "    # On crÃ©e l'histogramme et on ajoute les lignes pour la moyenne, le min et le max\n",
        "    series.hist(bins=100, color=color, alpha=0.75, ax=ax[0, i]).set(xlabel='Longueur des tokens', ylabel='Nombre de tokens', title=f'Histogramme: {column}')\n",
        "    ax[0, i].axvline(mean, color='black', linestyle='dashed', linewidth=2)\n",
        "    ax[0, i].axvline(min, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].axvline(max, color='black', linestyle='dotted', linewidth=1)\n",
        "    ax[0, i].text(mean, 2, f'Moyenne: {mean:.2f}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(min, 2, f'Min: {min}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    ax[0, i].text(max, 2, f'Max: {max}', rotation=90, verticalalignment='bottom', horizontalalignment='right', fontweight='bold')\n",
        "    # On crÃ©e le boxplot\n",
        "    series.plot(kind='box', vert=False, color=color, ax=ax[1, i]).set(xlabel='Longueur des tokens', title=f'Boxplot: {column}')\n",
        "    ax[1, i].set_yticks([])\n",
        "# On affiche la figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a pattern to match urls in the description column\n",
        "url = r\"www\\.\\S+\" # correct pattern for urls\n",
        "email = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n",
        "hashtag = r\"#\\S+\"\n",
        "mentions = r\"@\\S+\"\n",
        "emoji = r\"[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251]+\"\n",
        "\n",
        "# Find and display the urls that match the pattern in the product and description columns\n",
        "print(\"Recherche de pattern de type URL\")\n",
        "print(text_df[\"product_name\"].str.findall(url).apply(len).value_counts().index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define an email pattern to match emails in the description column\n",
        "email = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n",
        "\n",
        "# Find and display the urls that match the pattern in the product and description columns\n",
        "print(\"Recherche de pattern de type Email\")\n",
        "print(text_df[\"product_name\"].str.findall(email).apply(len).value_counts().index)\n",
        "print(text_df[\"description\"].str.findall(email).apply(len).value_counts().index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_custom(data, items_per_line=5):\n",
        "    \"\"\"\n",
        "    Affiche les Ã©lÃ©ments de la liste avec un nombre fixe d'Ã©lÃ©ments par ligne.\n",
        "    \n",
        "    :param data: La liste de donnÃ©es Ã  afficher.\n",
        "    :param items_per_line: Nombre d'Ã©lÃ©ments par ligne.\n",
        "    \"\"\"\n",
        "    for i in range(0, len(data), items_per_line):\n",
        "        print(data[i:i + items_per_line])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affiche tous les tokens de longueur supÃ©rieure ou Ã©gal Ã  13 caractÃ¨res\n",
        "print_custom(list(\n",
        "    set(\n",
        "    [token.text for doc in nlp.pipe(text_df['product_name'].values) for token in doc if len(token.text) >= 13]\n",
        "    ).union(set(\n",
        "        [token.text for doc in nlp.pipe(text_df['description'].values) for token in doc if len(token.text) >= 13])\n",
        "        )\n",
        ")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Corrige les exceptions suivantes lors de la tokenisation\n",
        "for column in ('product_name', 'description'):\n",
        "    text_df[column] = text_df[column].str.replace(r'(?<=\\w)[,-_.!()\"]+(?=\\w)', ' ', regex=True) # GÃ¨re les caractÃ¨res de type ,-_.!() qui sont au milieu d'une chaÃ®ne de caractÃ¨res\n",
        "    text_df[column] = text_df[column].str.replace(r'[,]+(?=\\w)', ' ', regex=True) # GÃ¨re les virgules qui sont au dÃ©but d'une chaÃ®ne de caractÃ¨res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affiche tous les tokens de longueur Ã©gal Ã  1 caractÃ¨re\n",
        "print_custom(list(\n",
        "    set(\n",
        "    [token.text for doc in nlp.pipe(text_df['product_name'].values) for token in doc if len(token.text) == 1]\n",
        "    ).union(set(\n",
        "        [token.text for doc in nlp.pipe(text_df['description'].values) for token in doc if len(token.text) == 1])\n",
        "        )\n",
        ")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Corrige les exceptions suivantes lors de la tokenisation\n",
        "for column in ('product_name', 'description'):\n",
        "    text_df[column] = text_df[column].str.replace(r'\\u2028', r'\\n', regex=True) # GÃ¨re les caractÃ¨res de type \\u2028 comme un saut de ligne\n",
        "    text_df[column] = text_df[column].str.replace(r'\\xa0', ' ', regex=True) # GÃ¨re les caractÃ¨res de type \\xa0 comme un espace\n",
        "    text_df[column] = text_df[column].str.replace(r'ï¿½', '', regex=True) # GÃ¨re les caractÃ¨res de type ï¿½ comme une chaÃ®ne vide"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "185b3fd51a024e08a306a6e0637acdd9": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e63383a6a9734f0f827bd482cc6b3ed5",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â ¸</span> Waiting for authorization\n</pre>\n",
                  "text/plain": "\u001b[32mâ ¸\u001b[0m Waiting for authorization\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "e63383a6a9734f0f827bd482cc6b3ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
