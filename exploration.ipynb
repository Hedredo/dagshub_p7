{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hedredo/dagshub_p7/blob/main/exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8toksSU9EOt"
      },
      "source": [
        "# **How-To MLflow**\n",
        "\n",
        "**How to use MLflow to log params and metrics**\n",
        "\n",
        "```\n",
        "with mlflow.start_run():\n",
        "  # Your training code here...\n",
        "  mlflow.log_metric('accuracy', 42)\n",
        "  mlflow.log_param('Param name', 'Value')\n",
        "```\n",
        "\n",
        "\n",
        "**Turn on autologging for most popular ML frameworks**<br>\n",
        "For more info and list of supported frameworks, see: https://mlflow.org/docs/latest/tracking.html#automatic-logging<br>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "mlflow.autolog()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuration de l'environnement**"
      ],
      "metadata": {
        "id": "3SeCRp5TWz-P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2JvR9_vR4VyK",
        "outputId": "a7c71968-f477-480b-b3db-b78bfc929777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.9/247.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.6/565.6 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q dagshub mlflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the CUDA version with the T4 GPU instance\n",
        "!nvcc --version"
      ],
      "metadata": {
        "id": "zSCY40Pa66Yv",
        "outputId": "02a06da3-0063-4b39-d108-50aae1d52822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dagshub\n",
        "import mlflow\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import spacy\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "AgChoQUZ97AN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tensorflow framework: GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
        "print(\"Pytorch framework: GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
      ],
      "metadata": {
        "id": "iQXWFolR6wXT",
        "outputId": "0b486aec-af3c-4a47-f49c-ba09a76d2d69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow framework: GPU is available\n",
            "Pytorch framework: GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove FutureWarning alerts\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# Initialize dagshub repo\n",
        "dagshub.init(repo_owner='hedredo', repo_name='dagshub_p7', mlflow=True)\n",
        "\n",
        "# Setting the gpu device for spacy\n",
        "spacy.prefer_gpu(gpu_id=0)\n",
        "\n",
        "# Set a random seed\n",
        "SEED = 314\n",
        "np.random.seed(SEED)\n",
        "print(\"Random seed set to\", SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "RaoRSbYq-DUX",
        "outputId": "89750207-2eb6-4c4c-a370-f25a6141737f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"hedredo/dagshub_p7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"hedredo/dagshub_p7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository hedredo/dagshub_p7 initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository hedredo/dagshub_p7 initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set to 314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "e7DZPq1vJMuN",
        "outputId": "2200f1d0-7781-4ca2-fc7e-bb65455fd730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the small language model for spacy\n",
        "spacy.cli.download('en_core_web_sm')"
      ],
      "metadata": {
        "id": "Cm25hDnuHRDQ",
        "outputId": "ecf808c0-1361-4b64-fae8-15a5b98e43de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement des données"
      ],
      "metadata": {
        "id": "-vtiCJZZ7iGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the csv file\n",
        "path = \"/content/drive/MyDrive/Formation & Emploi/OpenClassRooms/OC Projets de formation/Projet 7/training.1600000.processed.noemoticon.csv\""
      ],
      "metadata": {
        "id": "6xtWYfH2XGvn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the file\n",
        "df = pd.read_csv(\n",
        "    path,\n",
        "    header=None,\n",
        "    names=['target', 'ids', 'date', 'flag', 'user', 'text'],\n",
        "    parse_dates=['date'],\n",
        "    encoding='utf-8',\n",
        "    encoding_errors='replace' # replace the errors with unicode symbol � (U+FFFD)\n",
        "    )\n",
        "\n",
        "# Assign the len of the original file\n",
        "df_len = len(df)"
      ],
      "metadata": {
        "id": "xHMKuU6zXVgQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "9SzHxOZ2-pY2",
        "outputId": "c8e5bec3-fb34-454e-c145-347648df9c3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1600000 entries, 0 to 1599999\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count    Dtype         \n",
            "---  ------  --------------    -----         \n",
            " 0   target  1600000 non-null  int64         \n",
            " 1   ids     1600000 non-null  int64         \n",
            " 2   date    1600000 non-null  datetime64[ns]\n",
            " 3   flag    1600000 non-null  object        \n",
            " 4   user    1600000 non-null  object        \n",
            " 5   text    1600000 non-null  object        \n",
            "dtypes: datetime64[ns](1), int64(2), object(3)\n",
            "memory usage: 73.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- target : cible composée de 0:negative et 4:positive uniforme (environ 50 50)\n",
        "- id : identifiant unique pour chaque tweet. Un tweet peut être en double avec un même id annoté soit positif (4) soit négatif (0). C'est le seul champs qui peut varier.\n",
        "- date : la date du tweet (l'heure n'est pas fournie). PDT est l'heure du pacifique. Tous les tweets sont en PDT et la valeur est retiré lors du parsing\n",
        "- flag : toutes les valeurs sont à no query, useless\n",
        "- user : nom de l'utilisateur qui a posté le tweet. Peut être présent sur plusieurs tweets.\n",
        "- text : le texte du tweet"
      ],
      "metadata": {
        "id": "mKXXnXWKbq8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BLOC-NOTES**\n",
        "- Lire la description du projet\n",
        "- Regarder les notes google drive de PA\n",
        "- Faire un tableau markdown pour synthétiser le contenu\n",
        "- Importer uniquement les données utiles\n",
        "- Convertir les données dans le bon format\n",
        "- Faire une EDA et voir par exemple si le jour, l'heure, le mois ont un impact sur le sentiment\n",
        "- Faire une wordcloud pour voir les mots les plus fréquents selon la target\n",
        "- Faire un comptage de mots, ponctuation, hashtag, mention, url et regarder si leur nombre a un impact sur la classe\n",
        "- Préparer les corpus avec différentes options de prétraitement"
      ],
      "metadata": {
        "id": "GerSebNYbsQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Séparation des données**"
      ],
      "metadata": {
        "id": "wcLwgdx98mIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define if working with a sample\n",
        "sampling = True\n",
        "proportion = 0.1\n",
        "\n",
        "# Split the data with sampling or not\n",
        "if sampling:\n",
        "    if len(df) != df_len:\n",
        "        print(\"Dataframe has already been sampled\")\n",
        "    else:\n",
        "        print(f\"Sampling the data with {proportion} fraction\")\n",
        "        df = df.sample(frac=proportion, random_state=SEED)\n",
        "\n",
        "# Define X and y\n",
        "X = df['text']\n",
        "y = df['target']\n",
        "\n",
        "# Split the data with a 0.2 test size\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=SEED\n",
        "    )\n",
        "\n",
        "# Display shape of splits\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "rCL9XJz19D8v",
        "outputId": "30a49d4e-32a4-4076-8320-8d45fd5192e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe has already been sampled\n",
            "X_train shape: (128000,)\n",
            "X_test shape: (32000,)\n",
            "y_train shape: (128000,)\n",
            "y_test shape: (32000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Options de standardisation des textes**"
      ],
      "metadata": {
        "id": "oatQI0vyGvLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voici une liste de 10 moyens de standardiser votre corpus de tweets pour l'analyse de sentiments :\n",
        "\n",
        "1. **Conversion en minuscules** : Transformer tous les caractères en minuscules pour uniformiser le texte.\n",
        "2. **Suppression de la ponctuation** : Enlever tous les signes de ponctuation qui peuvent ne pas être pertinents pour l'analyse.\n",
        "3. **Élimination des mots vides (stop words)** : Supprimer les mots courants qui n'ajoutent pas de valeur sémantique significative (comme \"le\", \"la\", \"de\", etc.).\n",
        "4. **Stemming** : Réduire les mots à leur racine pour traiter les variations morphologiques (par exemple, \"aimant\", \"aimer\", \"aimé\" deviennent \"aim\").\n",
        "5. **Lemmatisation** : Transformer les mots en leur forme de base ou canonique (par exemple, \"étudiants\" devient \"étudiant\").\n",
        "6. **Suppression des nombres** : Enlever les chiffres qui peuvent ne pas être utiles pour l'analyse de sentiments.\n",
        "7. **Traitement des URL** : Remplacer les liens par un token spécifique comme `<URL>` pour uniformiser le texte.\n",
        "8. **Gestion des mentions** : Remplacer les @utilisateur par un token comme `<MENTION>` pour éviter les informations spécifiques inutiles.\n",
        "9. **Traitement des hashtags** : Extraire le mot-clé du hashtag (par exemple, \"#bonheur\" devient \"bonheur\") pour conserver le sens.\n",
        "10. **Gestion des emojis et émoticônes** : Remplacer les emojis par leur signification textuelle ou les supprimer si nécessaire (par exemple, \"😊\" devient \"heureux\").\n",
        "\n",
        "Ces standardisations peuvent vous aider à améliorer la qualité de vos données et potentiellement les performances de vos modèles de classification en réduisant le bruit et en uniformisant le corpus."
      ],
      "metadata": {
        "id": "ZqnO5skQ_ysV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "33fLtLp8G8sB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the gpu_id\n",
        "gpu_id = torch.cuda.current_device()\n",
        "print(gpu_id)"
      ],
      "metadata": {
        "id": "r5PX0QvkIoMl",
        "outputId": "623aff4b-7d0c-4996-836e-fea6072b7995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.prefer_gpu(gpu_id=0)\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "id": "QuUVzMvfIQ6m"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}